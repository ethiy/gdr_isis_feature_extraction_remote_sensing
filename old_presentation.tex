\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{standalone}

\usepackage[acronym]{glossaries}

\usepackage{enumitem}

\usepackage{xcolor}

\usepackage{multirow}
\usepackage{multicol}

\usepackage{array}
\newcolumntype{x}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\usepackage{booktabs}

\usepackage{siunitx}
\usepackage{mathrsfs, amsmath}

\usepackage{graphicx}
\usepackage[font={small, color=IGNDarkGrey}, labelformat=empty]{caption}
\usepackage{subcaption}
\DeclareCaptionFont{tiny}{\tiny}
\captionsetup[subtable]{labelfont={tiny, bf},textfont=normalfont,justification=raggedright}
\captionsetup[subfigure]{labelfont={tiny, bf},textfont=tiny,justification=raggedright}


\usepackage{hyperref}

\usepackage[
    mcite,
    backend=bibtex,
    style=verbose,
    citestyle=authoryear,
    bibstyle=numeric,
    sorting=none,
    autocite=footnote,
    maxnames=2,
    hyperref=true,
    natbib=true,
    abbreviate=true
]{biblatex}
\bibliography{references}
\setbeamerfont{footnote}{size=\tiny}


\usetheme{ign}


\newacronym{lod}{LoD}{Level of Detail}
\newacronym{elod}{eLoD}{evalution Level of Detail}
\newacronym{lidar}{LiDAR}{Light Detection and Ranging}
\newacronym{dsm}{DSM}{Digital Surface Model}
\newacronym{gui}{GUI}{Graphical User Interface}

\title{Semantic $3D$ building model qualification}
\subtitle{}
\institute[LaSTIG MATIS]{Univ. Paris Est, LaSTIG MATIS, IGN, ENSG}
\date{\today}
\author[O.Ennafii]{Oussama Ennafii}

\begin{document}

    \begin{frame}[plain]
        \titlepage{}
    \end{frame}

    \section{Introduction}
        \subsection{Context}
            \begin{frame}{$3D$ model vs. $3D$ mesh}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> $3D$ urban model $\equiv$ polyhedral surface representing a building;
                    \item<2-> Each facet in a $3D$ model is akin to an architechtural feature;
                    \item<3-> Holds higher semantic information than a $3D$ mesh while using less memory;
                \end{itemize}
                \uncover<4->{
                    \begin{figure}[H]
                        \begin{center}
                            \includegraphics[height=.2\textheight]{images/citygml_lod}
                            \caption{\label{fig::lods_citygml} \gls{lod}~\footfullcite{kolbe2005citygml} representation as defined in the \emph{cityGML} format~\footfullcite{ohori2016higher}.}
                        \end{center}
                    \end{figure}
                }
            \end{frame}

            \begin{frame}{What is urban reconstruction?}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> The aim is to model urban objects, on a large scale, using:
                    \begin{itemize}[label=--]
                        \item<2-> unstructured data: \gls{lidar};
                        \item<3-> structured data: stereoscopic images.
                    \end{itemize}
                    \item<3-> The model \gls{lod} depends on:
                    \begin{itemize}[label=--]
                        \item<4-> their intended use,
                        \item<5-> the input data spatial resolution.
                    \end{itemize}
                \end{itemize}
            \end{frame}

            \begin{frame}{Urban models applications}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Urban models have a wide application range~\footfullcite{Biljecki2015};
                \end{itemize}
                \uncover<2->{
                    \begin{table}
                        \begin{center}
                            \begin{tabular}{l l l}
                                \toprule
                                Planning & Simulation & Visualization \\
                                \midrule
                                City planning & Micro climates & Architecture \\
                                Emergency intervention & Wave propagation & Cadastre \\
                                Home decoration & Run-off water & Tourism \\
                                Communication network & Military intervention & Video games \\
                                \bottomrule
                            \end{tabular}
                            \caption{\label{tab::3d_applications} Some of the main thematic applications of $3D$ urban models.}
                        \end{center}
                    \end{table}
                }
            \end{frame}
        \subsection{Motivation}
            \begin{frame}{The need for modeling evaluation}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Automatic urban modeling is an active research area~\citep{Musialski2012}, but not \textcolor{IGNRed}{yet operational}~\citep{rottensteiner2014results}:
                    \begin{itemize}[label=--]
                        \item reconstruction methods lack generality and compacity;
                        \item too many modelling errors require labourious manual corrections.
                    \end{itemize}
                    \item<2-> Urban $3D$ model semantic diagnostic is not well studied~\citep{nguatem2017modeling}.
                \end{itemize}
                ~\\
                \uncover<3->{
                    \begin{itemize}[label=Goal $\longrightarrow$, font=\color{purple}, leftmargin=2cm]
                        \item Detect and describe semantic errors that affects building $3D$ models.
                    \end{itemize}
                }
            \end{frame}

            \begin{frame}{Potential use}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}, itemsep=2em]
                    \item<1-> Change detection;
                    \item<2-> Urban models correction;
                    \item<3-> Urban reconstruction method evaluation;
                    \item<4-> Crowd reconstruction quality assessment.
                \end{itemize}
            \end{frame}
    \section{State of the art}
        \begin{frame}{How to classify quality evaluation methods?}
            \begin{itemize}[
                    label=$\blacktriangleright$,
                    font=\color{IGNGreen},
                    itemsep=2em
                ]
                \item<1-> Based on the output:
                \begin{itemize}[label=--, itemsep=1em]
                    \item<2-> Geometric precision indices;
                    \item<2-> Semantic errors.
                \end{itemize}
                \item<3-> Based on the reference data:
                \begin{itemize}[label=--, itemsep=1em]
                    \item<4-> Manually obtained data;
                    \item<4-> Sensor data.
                \end{itemize}
            \end{itemize}
        \end{frame}
        \subsection{Different types of reference data}
            \begin{frame}{Manual data}
                Compare reconstructed $3D$ models with ground truth reference data with higher spatial accuracy, using:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> geodetic measurements ($ \sigma \sim \SI{0.05}{m}$)~\citep{Kaartinen2005, Voegtle2003};
                    \item<2-> stereo plotting~\citep{Kaartinen2005, Zeng2014}.
                \end{itemize}
                \uncover<3->{
                    Disadvantages:
                    \begin{itemize}[label=$-$, font=\color{IGNRed}]
                        \item<4-> too tedious to get.
                    \end{itemize}
                }
            \end{frame}

            \begin{frame}{Sensor data}
                Compare reconstructed $3D$ models with low semantic level sensor data, using:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> \gls{lidar}~\citep{Akca2010};
                    \item<2-> oriented aerial images~\citep{boudet2006supervised, Michelin2013}.
                \end{itemize}
                \uncover<3->{
                    Disadvantages:
                    \begin{itemize}[label=$-$, font=\color{IGNRed}]
                        \item<4-> no semantics.
                    \end{itemize}
                }
            \end{frame}
        \subsection{Different types of output}
            \begin{frame}{Geometric precision indices}
                Compute precision ratios from the $3D$ model which describes its quality.\\
                At different scales:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Points of interest average precision~\citep{Kaartinen2005, Voegtle2003},
                    \item<2-> Surface discrepency to reference data~\citep{Kaartinen2005, Henricsson1997,Zeng2014},
                    \item<3-> Volume discrepency to reference data~\citep{Zeng2014}.
                \end{itemize}
                \uncover<4->{
                    Disadvantages:
                    \begin{itemize}[label=$-$, font=\color{IGNRed}]
                        \item<5-> too general;
                        \item<6-> no semantics; thus no hierarchy.
                    \end{itemize}
                }
            \end{frame}

            \begin{frame}{Semantic errors}
                Identify the topologic and geometric errors that affects $3D$ models, using:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> visual inspection~\citep{OudeElberink2010};
                    \item<2-> supervised learning, detecting errors from a taxonomy based on:
                    \begin{itemize}[label=--]
                        \item<3-> traffic lights paradigm~\citep{boudet2006supervised};
                        \item<4-> a list of reconstruction errors~\citep{Michelin2013}.
                    \end{itemize}
                \end{itemize}
                \uncover<5->{
                    Risk:
                    \begin{itemize}[label=$-$, font=\color{IGNRed}]
                        \item<6-> overfitting to a scene or reconstruction method.
                    \end{itemize}
                }
            \end{frame}
        \subsection{Summary}
            \begin{frame}[plain]{Summary}
                \begin{figure}
                    \includegraphics[width=\textwidth]{state_of_the_art}
                    \caption{\label{fig::bib_summary} State of the art summary.}
                \end{figure}
            \end{frame}
            \begin{frame}{What do we want?}
                \begin{figure}
                    \includegraphics[width=.7\textwidth]{images/What-Do-We-Want}
                \end{figure}
            \end{frame}
            \begin{frame}{What do we want?}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}, itemsep=2em]
                    \item<1-> No reference data, or at least the most available sensor data;
                    \item<2-> Semantic errors independent from \textbf{reconstruction methods} and \textbf{urban scenes}.
                    \item<3-> Transferablility, and hence scallability, of the evalution method.
                \end{itemize}
            \end{frame}
    \section{Methodology}
        \subsection{Overview}
            \begin{frame}{The Qualification pipeline}
                \begin{figure}
                    \includegraphics[width=1.1\textwidth]{graphical_abstract}
                    \caption{\label{fig::pipeline} Pipeline describing the quality evaluation process.}
                \end{figure}
            \end{frame}
            \begin{frame}{Benefits of evaluation through prediction}
                The problem is modeled as a supervised learning one based on an established error taxonomy:
                \begin{enumerate}[label = (\roman*)., font=\color{IGNGreen}]
                    \item<2-> flexible: the error taxonomy is parametrizable;
                    \item<3-> independent: the taxonomy is agnostic towards reconstruction methods and modeled scenes;
                    \item<4-> fast: does not involve heavy computing at runtime;
                    \item<5-> modular: can use multiple entries:
                    \begin{itemize}[label=--]
                        \item<6-> the model itself;
                        \item<7-> the corresponding \gls{dsm} (stereoscopic or \gls{lidar} based);
                        \item<8-> the corresponding orthoimage.
                    \end{itemize}
                    \item<9-> lightweight: does not involve manual reference data at evaluation time.
                \end{enumerate}
            \end{frame}
        \subsection{Error Taxonomy}
            \begin{frame}{Bidimensional taxonomy}
                In order to establish our taxonomy, two criterea are taken into account:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> the \acrfull{lod};
                    \item<2-> the \emph{finesse}: the semantization level.
                    \begin{itemize}
                        \item<3-> an error is of maximal \emph{finesse} $\Rightarrow$ corresponds to a unit (semantically) action required for the operator to correct the model: $\equiv$ \emph{atomic} error.
                    \end{itemize}
                \end{itemize}
            \end{frame}
            \begin{frame}{Taxonomy \emph{finesse}}
                \begin{enumerate}[label = (\roman*)., font=\color{IGNGreen}]
                    \item<1-> \emph{finesse} $= 0$ $\longrightarrow$ \textbf{Unqualifiable} / \textbf{Qualifiable};
                    \item<2-> \emph{finesse} $= 1$ $\longrightarrow$ \textbf{Valid} / \textbf{Erroneous};
                    \item<3-> \emph{finesse} $= 2$:
                    \begin{itemize}[leftmargin=12em, font=\color{IGNDarkOrange}]
                        \item[$\gls{lod}0 \cup \gls{lod}1 \longrightarrow$] \textbf{Building Errors}
                        \item[$\gls{lod}2 \longrightarrow$] \textbf{Facet Errors}
                        \item[$\gls{lod}3 \longrightarrow$] \textbf{Superstructure Errors}
                    \end{itemize}
                    \begin{figure}[H]
                        \begin{center}
                            \includegraphics[height=.2\textheight]{images/citygml_lod}
                        \end{center}
                    \end{figure}
                    \item<4-> \emph{finesse} $= 3$ $\longrightarrow$ \emph{atomic} errors.
                \end{enumerate}

            \end{frame}
            \begin{frame}[plain]{\emph{Atomic} errors for $2.5D$ overhead reconstruction}
                \only<1-6>{
                    For a \gls{elod} $ = $ \gls{lod}-2, we propose:
                    \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                        \item<1-> \textbf{Building Errors}:
                        \begin{itemize}[leftmargin=10em, font=\color{IGNDarkGreen}]
                            \item[Under segmentation:]<2-> n > 1 buildings reconstructed as one;
                            \item[Over segmentation:]<3-> one building subdivided into n > 1;
                            \item[Imprecise footprint borders:]<4-> footprint borders are imprecise;
                            \item[Inaccurate footprint topology:]<5-> footprint suffers from topological defects: inner courts or wrong primitive fitting;
                            \item[Imprecise geometry:]<6-> inaccurate geometric estimation. If \textbf{\acrshort{elod}} $>$ \acrshort{lod}-0 $\cup$ \acrshort{lod}-1, this error is not reported (redundant with facet errors);
                        \end{itemize}
                    \end{itemize}
                }
                \only<7>{
                    \begin{figure}
                        \begin{center}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/building/under_segmentation}}
                                \caption{\label{fig::bul_under} Building under segmentation}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/building/over_segmentation}}
                                \caption{\label{fig::bul_over} Building over segmentation}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/building/footprint}}
                                \caption{\label{fig::bul_footprint} Imprecise footprint border}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/building/footprint_topology}}
                                \caption{\label{fig::bul_height} Inaccurate footprint topology}
                            \end{subfigure}
                            \caption{Building \emph{atomic} errors illustration.}
                        \end{center}
                    \end{figure}
                }
                \only<8-13>{
                    For a \gls{lod} $ = 2$, we propose:
                    \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                        \item<8-> \textbf{Facet Errors}:
                        \begin{itemize}[leftmargin=10em, font=\color{IGNDarkGreen}]
                            \item[Under segmentation:]<9-> n > 1 facets modeled as one;
                            \item[Over segmentation:]<10-> one facet subdivided into n > 1 ones;
                            \item[Imprecise borders:]<11-> borders are imprecise;
                            \item[Inaccurate topology:]<12-> the facet suffers from topological defects like a wrong primitive fitting;
                            \item[Imprecise geometry:]<13-> inaccurate facet geometric estimation.
                        \end{itemize}
                    \end{itemize}
                }
                \only<14>{
                    \begin{figure}
                        \begin{center}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/facet/under_segmentation}}
                                \caption{\label{fig::fac_under} Facet under segmentation}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/facet/over_segmentation}}
                                \caption{\label{fig::fac_over} Facet over segmentation}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/facet/mis_segmentation}}
                                \caption{\label{fig::fac_footprint} Facet imprecise borders}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/facet/topology}}
                                \caption{\label{fig::fac_height} Inaccurate topology}
                            \end{subfigure}
                            \hspace{10pt}
                            \begin{subfigure}{.28\textwidth}
                                \fbox{\includegraphics[width=\textwidth]{images/errors/facet/slope}}
                                \caption{\label{fig::fac_height} Imprecise geometry}
                            \end{subfigure}
                            \caption{Facet \emph{atomic} errors illustration.}
                        \end{center}
                    \end{figure}
                }
            \end{frame}
            \begin{frame}{Taxonomy parameters}
                The qualification has $3$ parameters:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> \emph{finesse}: the semantic level desired;
                    \item<2-> $\gls{elod}$: the evaluation level of details;
                    \item<3-> \emph{exclusivity}: report only the lowest \gls{lod} errors (\emph{exclusive}) or all errors (\emph{non exclusive}).
                \end{itemize}
            \end{frame}
            \begin{frame}{Taxonomy summary}
                \begin{figure}
                    \includestandalone[mode=buildnew, width=\textwidth]{taxonomy_tree}
                    \caption{\label{fig::tree_taxonomy} Summary for the hierarchical taxonomy.}
                \end{figure}
            \end{frame}
        \subsection{Features}
            \begin{frame}{Descriptor types}
                We define a baseline for:
                \begin{enumerate}[label = (\roman*)., font=\color{black}]
                    \item<1-> Basic intrinsic descriptor:
                    \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                        \item<2-> \textbf{Geometric} features based on the graph $\mathscr{G}=(facets, E)$\footnote{$E \triangleq \{\text{f and g are adjacent}: (f, g) \in facets \times facets\}$};
                    \end{itemize}
                    \item<3-> Optional descriptors:
                    \begin{itemize}[label=$\blacktriangleright$, font=\color{blue}]
                        \item<4-> \textbf{Altimetric} features;
                        \item<5-> \textbf{Radiometric} features;
                    \end{itemize}
                \end{enumerate}
            \end{frame}
            \begin{frame}{Geometric features}
                \begin{equation}\label{eq::feature_vec}
                    \text{features}(m) = \begin{bmatrix}
                            S(\{\vert \{e: e \in f\} \vert : f \in facets(m)\})\\
                            S(\{\mathscr{A}(f) : f \in facets(m)\})\\
                            S(\{\mathscr{C}(f) : f \in facets(m)\})\\
                            S(\{d(\mathscr{C}(f), \mathscr{C}(g)) : (f, g) \in facets(m)^2 \cap E(m)\})\\
                            S(\{acos(\vec{n}(f) . \vec{n}(g)) : (f, g) \in facets(m)^2 \cap E(m)\})
                    \end{bmatrix}
                \end{equation}
                \begin{itemize}
                    \only<1>{
                        \item where:
                        \begin{equation*}
                            S: x \mapsto \begin{bmatrix}
                                \max x\\
                                \min x\\
                                \overline{x}\\
                                median(x)
                            \end{bmatrix}
                        \end{equation*}
                    }
                    \only<2>{
                        \item or:
                        \begin{equation*}
                            S_{params}: x \mapsto histogram(x, params)
                        \end{equation*}
                    }
                \end{itemize}
            \end{frame}
            \begin{frame}{Altimetric features}
                \begin{equation}\label{eq::feature_vec}
                    \text{features}(m) = S_{params}(\gls{dsm} - z\ profile)
                \end{equation}
                \begin{itemize}[itemsep=5em]
                    \item where:
                    \begin{equation*}
                        S_{params}: x \mapsto histogram(x, params)
                    \end{equation*}
                    \item There is no theoretic bounds over the altimetric difference.
                    \begin{itemize}[font=\color{IGNDarkOrange}]
                        \item[$\Rightarrow$] We compute the bounds over the whole dataset in order to compute the histogram bins.
                    \end{itemize}
                \end{itemize}
            \end{frame}
            \begin{frame}{Altimetric features}
                \begin{figure}
                    \includegraphics[height=.7\textheight]{images/altimetric_features}
                    \caption{\label{fig::altimetric} Altimetric features illustration.}
                \end{figure}
            \end{frame}
            \begin{frame}[plain]{Radiometric features}
                \begin{figure}
                    \begin{subfigure}{.48\textwidth}
                        \includegraphics[width=\textwidth]{images/radio_vector}
                        \caption{\label{fig::ortho_sup} A building projection and the corresponding orthoimage.}
                    \end{subfigure}
                    \begin{subfigure}{.48\textwidth}
                        \includestandalone[mode=buildnew, width=\textwidth]{radiometric_features}
                        \caption{\label{fig::hist} We compute, for each segment in each facet, the scalar product of each intersecting pixel (in green) with the normalized image gradient at the same pixel.}
                    \end{subfigure}
                    \caption{\label{fig::radiometric} Radiometric features illustration.}
                \end{figure}
            \end{frame}
            \begin{frame}{Radiometric features}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> A histogram of gradient correlation is computed along each segment:
                    \begin{multline}
                        Corr_{params}(s) = hist \Bigg( \Big\{\frac{\nabla I(p) . \vec{n}(s)}{\vert\nabla I(p)\vert}: p \in I \text{ and } p \cap s \neq \emptyset \Big\}\\
                        , params\Bigg)
                    \end{multline}
                    \item<2-> For each model $m$, we compute then:
                    \begin{equation}
                        Corr_{params}(m) = \mathscr{P}(m) . \sum_{Pol \in m} \mathscr{A}(Pol). \sum_{s \in Pol} \vert\vert s \vert\vert_2. Corr_{params}(s)
                    \end{equation}
                \end{itemize}
            \end{frame}
        \subsection{Classifiers}
            \begin{frame}{Random Forest}
                Any supervised classifier can be used in our problem. We opted for a Random Forest classifier, because:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> it handles well multimodal features;
                    \item<2-> being based on a boosting method, it is build to avoid overfitting;
                    \item<3-> it computes quite easily feature importance.
                \end{itemize}
                \uncover<4->{
                    Parameters:
                    \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                        \item<5-> $4$ maximum depth to avoid overfitting the trees;
                        \item<6-> $1000$ trees to cover the whole the attributes space.
                    \end{itemize}
                }
            \end{frame}
            \begin{frame}{Multi-Class, Multi-Label or Multi-Stage}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Depending on the \emph{finesse} and the \emph{exclusivity} parameters, we get a:
                    \begin{itemize}[label=--]
                        \item<2-> \textbf{Multi-Class} problem: one label to predict, multiple cases to predict;
                        \item<3-> \textbf{Multi-Label} problem: multiple labels to predict, each is, in our case, \textbf{binary};
                        \item<4-> \textbf{Multi-Stage} or Hierchical problem: one \textbf{Multi-Class} stage to predict the \emph{error family} and then a \textbf{Multi-Label} one to detect the corresponding \emph{atomic} errors.
                    \end{itemize}
                    \item<5-> We adapt any \textbf{Multi-Class} or \textbf{binary} classifier to be the \textbf{Multi-Label} setting using a \emph{OnevsAll} strategy.
                \end{itemize}
            \end{frame}
    \section{Experiments}
        \subsection{Data}
            \begin{frame}{Used Data}
                \begin{itemize}[leftmargin=6em, font=\color{IGNDarkGreen}]
                    \item[Town:]<1-> Elancourt (Yvelines, France);
                    \item[Area:]<2-> \SI{15}{\km\squared};
                    \item[Buildings:]<3-> $1501$;
                    \item[Type:]<4-> mostly residential and insutrial districts with some administrative buildings;
                    \item[Algorithm:]<5-> $\text{Bati3D}^\text{\textregistered}$~\footfullcite{Durupt2006}.
                \end{itemize}
            \end{frame}
            \begin{frame}[plain]{Ground truth statistics}
                \begin{table}
                    \scriptsize
                    \begin{center}
                        \begin{tabular}{|x{1.8cm} | x{1.4cm} | x{2cm} | x{2cm} | x{2cm}|}
                            \hline
                            \multicolumn{1}{|c|}{\textbf{Error Family}} & \textbf{Occurrence ratio} & \textbf{\emph{Atomic} error} & \textbf{Family conditional occurrence ratio} & \textbf{Absolute occurrence ratio} \\
                            \hline
                            Unqualifiable & $0.0180$ & --- & --- & --- \\
                            \hline
                            \hline
                            \multirow{4}{*}{\shortstack{Building\\Errors}} & \multirow{4}{*}{$0.8235$} & Over segmentation & $0.8285$ & $0.6822$\\
                            \cline{3-5}
                                &                   & Under segmentation & $0.2824$ & $0.2325$ \\
                            \cline{3-5}
                                &                   & Imprecise footprint & $0.1521$ & $0.1252$ \\
                            \cline{3-5}
                                &                   & Imprecise height & $0.0057$ & $0.0047$ \\
                            \hline
                            \hline
                            \multirow{4}{*}{Facet Errors} & \multirow{4}{*}{$0.7249$} & Over segmentation & $0.8971$ & $0.6502$ \\
                            \cline{3-5}
                                &                   & Under segmentation & $0.1314$ & $0.0953$ \\
                            \cline{3-5}
                                &                   & Imprecise segmentation & $0.1351$ & $0.9793$ \\
                            \cline{3-5}
                                &                   & Imprecise slope & $0.0193$ & $0.0140$ \\
                            \hline
                        \end{tabular}
                    \end{center}
                \end{table}            
            \end{frame}
        \subsection{Results}
            \begin{frame}[plain]{Results at $\textit{finesse}=2$}
                \begin{table}
                    \scriptsize
                    \begin{center}
                        \begin{tabular}{|x{1cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm}|}
                            \hline
                            &\multicolumn{2}{x{1.6cm}|}{\textbf{Geometry}} & \multicolumn{2}{x{1.6cm}|}{\textbf{Geom. $\cup$ Height}} & \multicolumn{2}{x{1.6cm}|}{\textbf{Geom. $\cup$ Image}} & \multicolumn{2}{|x{1.6cm}|}{\textbf{All}}\\
                            \cline{2-9}
                            &\textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.}\\
                            \hline
                            Building errors & $99.76$ & \textbf{84.16} & $99.76$ & $84.11$& $99.92$ & $83.84$ & \textbf{100} & $83.85$ \\
                            \hline
                            Facet errors & $90.81$ & $98.02$ & \textbf{91.08} & \textbf{98.41} & $90.44$ & $97.62$ & $90.53$ & $97.82$ \\
                            \hline
                        \end{tabular}
                    \end{center}
                \end{table}
            \end{frame}
            \begin{frame}[plain]{Results at $\textit{finesse}=3$}
                \begin{table}
                    \scriptsize
                    \begin{center}
                        \begin{tabular}{|x{1.4cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm} | x{.8cm} x{.8cm}|}
                            \hline
                            &\multicolumn{2}{x{1.6cm}|}{\textbf{Geometry}} & \multicolumn{2}{x{1.6cm}|}{\textbf{Geom. $\cup$ Height}} & \multicolumn{2}{x{1.6cm}|}{\textbf{Geom. $\cup$ Image}} & \multicolumn{2}{|x{1.6cm}|}{\textbf{All}}\\
                            \cline{2-9}
                            &\textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.} & \textbf{Recall} & \textbf{Prec.}\\
                            \hline
                            \textit{BOS} & \textbf{94.34} & $77.09$ &$93.36$ & \textbf{77.66} &$92.38$ & $77.04$ &$92.19$ & $76.69$ \\
                            \hline
                            \textit{BUS} & $34.38$ & $76.43$ &$31.52$ & \textbf{78.57} & \textbf{42.98} & $76.53$ &$41.55$ & $77.96$ \\
                            \hline
                            \textit{BInf} & \textbf{22.34} & \textbf{68.85} & $22.34$ & $67.74$ &$18.09$ & $64.15$ &$18.62$ & $64.81$ \\
                            \hline
                            \textit{BImH} & $0$ & --- & $0$ & --- & $0$ & --- &$0$ & $0$ \\
                            \hline
                            \hline
                            \textit{FOS} & $98.77$ & \textbf{98.77} & \textbf{98.87} & $98.67$ &$98.67$ & $98.47$ &$98.67$ & $98.37$ \\
                            \hline
                            \textit{FUS} & \textbf{0.70} & \textbf{50.00} &$0.70$ & $33.34$ & \textbf{0.70} & \textbf{50.00} & \textbf{0.70} & \textbf{50.00} \\
                            \hline
                            \textit{FIS} & \textbf{1.36} & \textbf{66.67} &$1.36$ & $50.00$ &$1.36$ & $28.57$ &$1.36$ & $40.00$ \\
                            \hline
                            \textit{FImS} & $0$ & --- & $0$ & --- & $0$ & --- &$0$ & --- \\
                            \hline
                        \end{tabular}
                    \end{center}
                \end{table}
            \end{frame}
            \begin{frame}{Discussion}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Familly errors are detected better at $\textit{finesse}=2$;
                    \item<2-> Among the \textbf{Facet Errors}, all but \textbf{Facet Over segmentation} suffer from the unbalanced dataset ($ < 7\%$ among the $1501$ instances) $\Rightarrow$ small recall and big overall accuracy.
                    \item<3-> Geometric features alone can predict errors with a comparable order of accuracy as with other combinations. It is only outperformed for a limited individual cases (\textbf{Building under segmentation}: $\Delta recall > 20\%$).
                \end{itemize}
            \end{frame}
    \section{Perspectives}
        \subsection{Data augmentation}
            \begin{frame}{The need for more data}
                We need more data:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item to have enough representative samples for each error for the learning step;
                    \item to avoid overfitting to a specific urban scene or a specific reconstruction method.
                \end{itemize}
            \end{frame}
            \begin{frame}{Bottleneck: annotations}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> One difficult aspect of the methodology is the annotation phase.
                    \item<2-> A Master's (PPMD) student made a \emph{QT5} \acrshort{gui} python application. It can be used:
                    \begin{itemize}[label=--]
                        \item<3-> for annotation purposes,
                        \item<4-> for error prediction verification in an operational setup,
                        \item<5-> in a semi-supervised learning pipeline.
                    \end{itemize}
                    \item<6-> We can also consider error simulation using TRAPU as a reference data.
                \end{itemize}
            \end{frame}
            \begin{frame}{Transferablility}
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> We need to procure more reconstructed scenes using $\text{Bati3D}^\text{\textregistered}$: Nanted, Paris 13, Paris 11-10-20-12.
                    \item<2-> A group of students (ENSG) reconstructed Elancourt using the \emph{3dfier} program~\citep{ledoux2011topologically}: $\gls{lod} = 1$;
                    \item<3-> Florent Lafarge is helping generate more models using other methods~\citep{Lafarge2012}.
                \end{itemize}
            \end{frame}
        \subsection{Learned features}
            \begin{frame}{Graph kernels \& Deep learning}
                We consider investigating:
                \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                    \item<1-> Graph kernels:
                    \begin{itemize}
                        \item[\color{green} +]<2-> it can be feasible: we mostly have small graphs.
                        \item[\color{green} +]<3-> it takes advantage of the model structure better than simple histograms;
                        \item[\color{red} --]<4-> it requires high computational capacity.
                    \end{itemize}
                    \item<5-> Deep learning:
                    \begin{itemize}
                        \item[\color{green} +]<6-> its capacity has been proven for images;
                        \item[\color{green} +]<7-> it is highly semantic and transferable;
                        \item[\color{red} --]<8-> it requires a big number of instances.
                    \end{itemize}
                \end{itemize}
            \end{frame}
    \section{Conclusion}
        \begin{frame}{Conclusion}
            \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                \item<1-> We propose a new qualification framework for building $3D$ polyhedral models;
                \item<2-> We categorize $3D$ model errors into a flexible taxonomy independent from the reconstruction method;
                \item<3-> We propose a fast, lightweight and modular classification pipeline using supervised learning;
                \item<4-> We established a baseline for geometric, radiometric and altimetric features.
            \end{itemize}
        \end{frame}
        \begin{frame}{Used tools}
            \begin{itemize}[label=$\blacktriangleright$, font=\color{IGNGreen}]
                \item<1-> 3D scene preparation: computes projections and rasterizes them $\longrightarrow$ C++ project \textbf{proj.city} hosted by GitHub under GPLv3.0;
                \item<2-> Geoinformation handling: because GDAL is appaling $\longrightarrow$ Python miniproject \textbf{geo2d} hosted by GitHub under GPLv3.0;
                \item<3-> GIS image annotation tool: because QGIS is also appaling $\longrightarrow$ \textbf{sGrISner} pyqt5 app hosted by GitHub under GPLv3.0;
                \item<4-> DSM to Pointcloud: because I did not find one $\longrightarrow$ \textbf{dsm2pc} minipython app hosted by GitHub under GPLv3.0; 
                \item<5-> Python project for building qualification: \textbf{qualcity} hosted by GitHub (private).
            \end{itemize}
        \end{frame}
    \section*{References}
        \begin{frame}[allowframebreaks]{References}
            \printbibliography
        \end{frame}
    \appendix
\end{document}
